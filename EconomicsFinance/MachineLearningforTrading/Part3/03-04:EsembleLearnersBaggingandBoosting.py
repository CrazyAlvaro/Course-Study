# Ensemble learners

# KNN LinReg, Dicision Tree, SVM
# lower error, less overfitting,

# Boostrap aggregating

# Bagging exampleï¼š esemble several models

# Boosting: Ada Boost: weight wrong elements more weight to train next model

# wrap existing models, reduce errors, reduce overfitting
